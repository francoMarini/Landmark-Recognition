{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "MobileNetNoAugumentation.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZn1THMYXiMP"
      },
      "source": [
        "# Librerie\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80a2Wa9dXoCt",
        "outputId": "54024a19-571f-4214-c9c1-9f7a8a06106a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HgIf4VE7uxN6",
        "outputId": "c9f842b4-8152-4d02-fd5d-42e00040209b"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue Apr 13 17:32:30 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.67       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   55C    P8    31W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BnAn24hWXiMf"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense,Conv2D,MaxPooling2D,Flatten,Dropout #Riga interessante\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Sequential\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sILCkFC9qP0q",
        "outputId": "672d608b-acb7-4091-deaa-3ec3b8386d22"
      },
      "source": [
        "train_path= '/content/drive/MyDrive/Colab Notebooks/Landmark Recognition/data/train'\n",
        "valid_path= '/content/drive/MyDrive/Colab Notebooks/Landmark Recognition/data/val'\n",
        "test_path= '/content/drive/MyDrive/Colab Notebooks/Landmark Recognition/data/test'\n",
        "\n",
        "data_generator = ImageDataGenerator()\n",
        "\n",
        "train_set = data_generator.flow_from_directory(directory=train_path, target_size=(128,128), class_mode='categorical', batch_size=10)\n",
        "valid_set = data_generator.flow_from_directory(directory=valid_path, target_size=(128,128), class_mode='categorical', batch_size=10)\n",
        "test_set = data_generator.flow_from_directory(directory=test_path, target_size=(128,128), class_mode='categorical', batch_size=1, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 11387 images belonging to 100 classes.\n",
            "Found 1380 images belonging to 100 classes.\n",
            "Found 1515 images belonging to 100 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKleUo5BXiMk"
      },
      "source": [
        "# Modello"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imCTYozfrhSB",
        "outputId": "a2319877-f528-4302-f7f7-3abef5a06c96"
      },
      "source": [
        "mobile = tf.keras.applications.mobilenet.MobileNet()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet/mobilenet_1_0_224_tf.h5\n",
            "17227776/17225924 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HacADckitg0S"
      },
      "source": [
        "#STEP 1\n",
        "x = mobile.layers[-6].output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2j3tlFZthXj"
      },
      "source": [
        "#STEP 2\n",
        "output = Dense(units=100, activation='softmax')(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2o02DYVxt3nR"
      },
      "source": [
        "model = Model(inputs=mobile.input, outputs=output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CyV7rxqPXiMm",
        "outputId": "08269aaf-7ae0-4d56-947a-5c4ca74c2859"
      },
      "source": [
        "#Vediamo la struttura della rete\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "conv1 (Conv2D)               (None, 112, 112, 32)      864       \n",
            "_________________________________________________________________\n",
            "conv1_bn (BatchNormalization (None, 112, 112, 32)      128       \n",
            "_________________________________________________________________\n",
            "conv1_relu (ReLU)            (None, 112, 112, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv_dw_1 (DepthwiseConv2D)  (None, 112, 112, 32)      288       \n",
            "_________________________________________________________________\n",
            "conv_dw_1_bn (BatchNormaliza (None, 112, 112, 32)      128       \n",
            "_________________________________________________________________\n",
            "conv_dw_1_relu (ReLU)        (None, 112, 112, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv_pw_1 (Conv2D)           (None, 112, 112, 64)      2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_1_bn (BatchNormaliza (None, 112, 112, 64)      256       \n",
            "_________________________________________________________________\n",
            "conv_pw_1_relu (ReLU)        (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv_pad_2 (ZeroPadding2D)   (None, 113, 113, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv_dw_2 (DepthwiseConv2D)  (None, 56, 56, 64)        576       \n",
            "_________________________________________________________________\n",
            "conv_dw_2_bn (BatchNormaliza (None, 56, 56, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv_dw_2_relu (ReLU)        (None, 56, 56, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv_pw_2 (Conv2D)           (None, 56, 56, 128)       8192      \n",
            "_________________________________________________________________\n",
            "conv_pw_2_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv_pw_2_relu (ReLU)        (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_3 (DepthwiseConv2D)  (None, 56, 56, 128)       1152      \n",
            "_________________________________________________________________\n",
            "conv_dw_3_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv_dw_3_relu (ReLU)        (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_3 (Conv2D)           (None, 56, 56, 128)       16384     \n",
            "_________________________________________________________________\n",
            "conv_pw_3_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv_pw_3_relu (ReLU)        (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv_pad_4 (ZeroPadding2D)   (None, 57, 57, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_4 (DepthwiseConv2D)  (None, 28, 28, 128)       1152      \n",
            "_________________________________________________________________\n",
            "conv_dw_4_bn (BatchNormaliza (None, 28, 28, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv_dw_4_relu (ReLU)        (None, 28, 28, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_4 (Conv2D)           (None, 28, 28, 256)       32768     \n",
            "_________________________________________________________________\n",
            "conv_pw_4_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
            "_________________________________________________________________\n",
            "conv_pw_4_relu (ReLU)        (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_5 (DepthwiseConv2D)  (None, 28, 28, 256)       2304      \n",
            "_________________________________________________________________\n",
            "conv_dw_5_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
            "_________________________________________________________________\n",
            "conv_dw_5_relu (ReLU)        (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_5 (Conv2D)           (None, 28, 28, 256)       65536     \n",
            "_________________________________________________________________\n",
            "conv_pw_5_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
            "_________________________________________________________________\n",
            "conv_pw_5_relu (ReLU)        (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv_pad_6 (ZeroPadding2D)   (None, 29, 29, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_6 (DepthwiseConv2D)  (None, 14, 14, 256)       2304      \n",
            "_________________________________________________________________\n",
            "conv_dw_6_bn (BatchNormaliza (None, 14, 14, 256)       1024      \n",
            "_________________________________________________________________\n",
            "conv_dw_6_relu (ReLU)        (None, 14, 14, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_6 (Conv2D)           (None, 14, 14, 512)       131072    \n",
            "_________________________________________________________________\n",
            "conv_pw_6_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_6_relu (ReLU)        (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_7 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_7_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_7_relu (ReLU)        (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_7 (Conv2D)           (None, 14, 14, 512)       262144    \n",
            "_________________________________________________________________\n",
            "conv_pw_7_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_7_relu (ReLU)        (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_8 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_8_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_8_relu (ReLU)        (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_8 (Conv2D)           (None, 14, 14, 512)       262144    \n",
            "_________________________________________________________________\n",
            "conv_pw_8_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_8_relu (ReLU)        (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_9 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_9_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_9_relu (ReLU)        (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_9 (Conv2D)           (None, 14, 14, 512)       262144    \n",
            "_________________________________________________________________\n",
            "conv_pw_9_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_9_relu (ReLU)        (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_10 (DepthwiseConv2D) (None, 14, 14, 512)       4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_10_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_10_relu (ReLU)       (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_10 (Conv2D)          (None, 14, 14, 512)       262144    \n",
            "_________________________________________________________________\n",
            "conv_pw_10_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_10_relu (ReLU)       (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_11 (DepthwiseConv2D) (None, 14, 14, 512)       4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_11_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_11_relu (ReLU)       (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_11 (Conv2D)          (None, 14, 14, 512)       262144    \n",
            "_________________________________________________________________\n",
            "conv_pw_11_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_11_relu (ReLU)       (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_pad_12 (ZeroPadding2D)  (None, 15, 15, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_12 (DepthwiseConv2D) (None, 7, 7, 512)         4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_12_bn (BatchNormaliz (None, 7, 7, 512)         2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_12_relu (ReLU)       (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv_pw_12 (Conv2D)          (None, 7, 7, 1024)        524288    \n",
            "_________________________________________________________________\n",
            "conv_pw_12_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
            "_________________________________________________________________\n",
            "conv_pw_12_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
            "_________________________________________________________________\n",
            "conv_dw_13 (DepthwiseConv2D) (None, 7, 7, 1024)        9216      \n",
            "_________________________________________________________________\n",
            "conv_dw_13_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
            "_________________________________________________________________\n",
            "conv_dw_13_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
            "_________________________________________________________________\n",
            "conv_pw_13 (Conv2D)          (None, 7, 7, 1024)        1048576   \n",
            "_________________________________________________________________\n",
            "conv_pw_13_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
            "_________________________________________________________________\n",
            "conv_pw_13_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 100)               102500    \n",
            "=================================================================\n",
            "Total params: 3,331,364\n",
            "Trainable params: 3,309,476\n",
            "Non-trainable params: 21,888\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZ00ys0UXiMo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eaa195f8-1a93-425f-e033-1736f962a282"
      },
      "source": [
        "#Sono 88 layers incluso l'input\n",
        "len(model.layers)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "88"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LM3dqN1uXiMs"
      },
      "source": [
        "for layer in model.layers[:-23]:\n",
        "    layer.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6C60DX8XiMt"
      },
      "source": [
        "#Compile and fit the datasets\n",
        "model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-crYFYPXiMu",
        "outputId": "93f75eda-5c57-4559-c84c-47a0ef61aa94"
      },
      "source": [
        "step_size_train=train_set.n//train_set.batch_size\n",
        "step_size_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1138"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nq9QxivoXiMw",
        "outputId": "e4182517-888e-460b-ae95-0a720bd6c4eb"
      },
      "source": [
        "step_size_valid=valid_set.n//valid_set.batch_size\n",
        "step_size_valid"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "138"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "doPQm_xmXiMx",
        "outputId": "97fb068a-db98-412b-8056-2121b22dc279"
      },
      "source": [
        "model.fit(x=train_set, steps_per_epoch=step_size_train, validation_data= valid_set, validation_steps=step_size_valid, epochs=30)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "1138/1138 [==============================] - 7959s 7s/step - loss: 3.0878 - accuracy: 0.3400 - val_loss: 1.9655 - val_accuracy: 0.5406\n",
            "Epoch 2/30\n",
            "1138/1138 [==============================] - 296s 260ms/step - loss: 1.1903 - accuracy: 0.6810 - val_loss: 1.6234 - val_accuracy: 0.6246\n",
            "Epoch 3/30\n",
            "1138/1138 [==============================] - 285s 250ms/step - loss: 0.7384 - accuracy: 0.7921 - val_loss: 1.9710 - val_accuracy: 0.5862\n",
            "Epoch 4/30\n",
            "1138/1138 [==============================] - 286s 251ms/step - loss: 0.5142 - accuracy: 0.8509 - val_loss: 1.9372 - val_accuracy: 0.5986\n",
            "Epoch 5/30\n",
            "1138/1138 [==============================] - 287s 252ms/step - loss: 0.3744 - accuracy: 0.8884 - val_loss: 2.0019 - val_accuracy: 0.6319\n",
            "Epoch 6/30\n",
            "1138/1138 [==============================] - 286s 251ms/step - loss: 0.2733 - accuracy: 0.9195 - val_loss: 1.8986 - val_accuracy: 0.6696\n",
            "Epoch 7/30\n",
            "1138/1138 [==============================] - 287s 252ms/step - loss: 0.2330 - accuracy: 0.9291 - val_loss: 2.0279 - val_accuracy: 0.6536\n",
            "Epoch 8/30\n",
            "1138/1138 [==============================] - 287s 253ms/step - loss: 0.1948 - accuracy: 0.9427 - val_loss: 1.8015 - val_accuracy: 0.7000\n",
            "Epoch 9/30\n",
            "1138/1138 [==============================] - 286s 251ms/step - loss: 0.1600 - accuracy: 0.9492 - val_loss: 1.7532 - val_accuracy: 0.6942\n",
            "Epoch 10/30\n",
            "1138/1138 [==============================] - 285s 251ms/step - loss: 0.1745 - accuracy: 0.9454 - val_loss: 1.5236 - val_accuracy: 0.7116\n",
            "Epoch 11/30\n",
            "1138/1138 [==============================] - 286s 251ms/step - loss: 0.1244 - accuracy: 0.9619 - val_loss: 1.8356 - val_accuracy: 0.6891\n",
            "Epoch 12/30\n",
            "1138/1138 [==============================] - 286s 251ms/step - loss: 0.1449 - accuracy: 0.9551 - val_loss: 1.6550 - val_accuracy: 0.7377\n",
            "Epoch 13/30\n",
            "1138/1138 [==============================] - 287s 252ms/step - loss: 0.1195 - accuracy: 0.9639 - val_loss: 1.7636 - val_accuracy: 0.7246\n",
            "Epoch 14/30\n",
            "1138/1138 [==============================] - 283s 249ms/step - loss: 0.1149 - accuracy: 0.9637 - val_loss: 1.5654 - val_accuracy: 0.7326\n",
            "Epoch 15/30\n",
            "1138/1138 [==============================] - 277s 243ms/step - loss: 0.0840 - accuracy: 0.9748 - val_loss: 2.0203 - val_accuracy: 0.6906\n",
            "Epoch 16/30\n",
            "1138/1138 [==============================] - 282s 248ms/step - loss: 0.0933 - accuracy: 0.9721 - val_loss: 1.8197 - val_accuracy: 0.7246\n",
            "Epoch 17/30\n",
            "1138/1138 [==============================] - 285s 251ms/step - loss: 0.0921 - accuracy: 0.9735 - val_loss: 1.7278 - val_accuracy: 0.7138\n",
            "Epoch 18/30\n",
            "1138/1138 [==============================] - 285s 251ms/step - loss: 0.0801 - accuracy: 0.9776 - val_loss: 2.0570 - val_accuracy: 0.7196\n",
            "Epoch 19/30\n",
            "1138/1138 [==============================] - 285s 251ms/step - loss: 0.0754 - accuracy: 0.9753 - val_loss: 1.9719 - val_accuracy: 0.7159\n",
            "Epoch 20/30\n",
            "1138/1138 [==============================] - 285s 250ms/step - loss: 0.0831 - accuracy: 0.9747 - val_loss: 1.8775 - val_accuracy: 0.7225\n",
            "Epoch 21/30\n",
            "1138/1138 [==============================] - 286s 251ms/step - loss: 0.0737 - accuracy: 0.9759 - val_loss: 1.7278 - val_accuracy: 0.7500\n",
            "Epoch 22/30\n",
            "1138/1138 [==============================] - 286s 251ms/step - loss: 0.0678 - accuracy: 0.9781 - val_loss: 1.8028 - val_accuracy: 0.7341\n",
            "Epoch 23/30\n",
            "1138/1138 [==============================] - 284s 249ms/step - loss: 0.0502 - accuracy: 0.9836 - val_loss: 1.8760 - val_accuracy: 0.7268\n",
            "Epoch 24/30\n",
            "1138/1138 [==============================] - 281s 247ms/step - loss: 0.0540 - accuracy: 0.9826 - val_loss: 1.8629 - val_accuracy: 0.7261\n",
            "Epoch 25/30\n",
            "1138/1138 [==============================] - 280s 246ms/step - loss: 0.0453 - accuracy: 0.9863 - val_loss: 1.9645 - val_accuracy: 0.7333\n",
            "Epoch 26/30\n",
            "1138/1138 [==============================] - 280s 246ms/step - loss: 0.0586 - accuracy: 0.9809 - val_loss: 1.5895 - val_accuracy: 0.7406\n",
            "Epoch 27/30\n",
            "1138/1138 [==============================] - 280s 246ms/step - loss: 0.0435 - accuracy: 0.9857 - val_loss: 1.5999 - val_accuracy: 0.7638\n",
            "Epoch 28/30\n",
            "1138/1138 [==============================] - 277s 243ms/step - loss: 0.0431 - accuracy: 0.9864 - val_loss: 2.1970 - val_accuracy: 0.7094\n",
            "Epoch 29/30\n",
            "1138/1138 [==============================] - 276s 242ms/step - loss: 0.0611 - accuracy: 0.9829 - val_loss: 1.7101 - val_accuracy: 0.7486\n",
            "Epoch 30/30\n",
            "1138/1138 [==============================] - 277s 243ms/step - loss: 0.0441 - accuracy: 0.9857 - val_loss: 1.9161 - val_accuracy: 0.7312\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f4e9fae0790>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FKWW7EqaiKGu",
        "outputId": "e4d31ccf-f03e-46a9-a915-2c27bf39e0ce"
      },
      "source": [
        "test_datagen= ImageDataGenerator()\n",
        "\n",
        "test_set= test_datagen.flow_from_directory('/content/drive/MyDrive/Colab Notebooks/Landmark Recognition/data/test', \n",
        "                                             target_size=(128,128), batch_size=1, class_mode='categorical', \n",
        "                                             shuffle=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1515 images belonging to 100 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "maBSvM9jlj7h",
        "outputId": "64f42a31-f54a-4264-883d-adc594fdbafe"
      },
      "source": [
        "test_set.reset()\n",
        "test_steps_per_epoch = np.math.ceil(test_set.samples / test_set.batch_size)\n",
        "print(test_steps_per_epoch)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1515\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jhFJPNZjyNw"
      },
      "source": [
        "predictions = model.predict(x=test_set, steps=test_steps_per_epoch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j33IUblyiKSZ",
        "outputId": "9ed47960-8b4e-4d27-a8c3-df7efcc212bc"
      },
      "source": [
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "print(predicted_classes)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 0  0  0 ... 99 99 99]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-AAfyAwiKWe"
      },
      "source": [
        "true_classes = test_set.classes\n",
        "class_labels = list(test_set.class_indices.keys())   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "reMGm3bWiKZy",
        "outputId": "588f59c7-c7a5-4b69-ab89-90c10261dca2"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "report = classification_report(true_classes, predicted_classes, target_names=class_labels)\n",
        "print(report)    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       10018       0.30      0.73      0.42        11\n",
            "       10094       0.61      0.69      0.65        16\n",
            "       10602       0.72      0.87      0.79        15\n",
            "       11300       1.00      1.00      1.00        16\n",
            "       11378       0.56      0.88      0.68        16\n",
            "       11491       0.78      0.50      0.61        14\n",
            "       11499       0.86      0.75      0.80        16\n",
            "       11513       0.67      0.62      0.64        13\n",
            "        1168       0.54      0.44      0.48        16\n",
            "       11716       0.67      0.67      0.67        12\n",
            "       11719       0.93      0.76      0.84        17\n",
            "       11750       0.93      0.76      0.84        17\n",
            "       11849       0.67      0.67      0.67        15\n",
            "       11967       0.58      0.93      0.72        15\n",
            "       12181       0.77      0.71      0.74        14\n",
            "       12204       0.94      0.88      0.91        17\n",
            "       12360       0.60      0.75      0.67        16\n",
            "       12481       0.67      0.94      0.78        17\n",
            "       12531       0.73      0.73      0.73        15\n",
            "       12536       1.00      0.69      0.81        16\n",
            "       13079       1.00      0.85      0.92        13\n",
            "       13114       0.80      0.75      0.77        16\n",
            "       13218       0.91      0.67      0.77        15\n",
            "         133       0.81      0.87      0.84        15\n",
            "       13776       0.44      0.82      0.57        17\n",
            "       13840       0.43      0.80      0.56        15\n",
            "       13963       0.79      0.79      0.79        14\n",
            "       14061       1.00      0.69      0.81        16\n",
            "        1415       0.86      0.80      0.83        15\n",
            "       14193       0.58      0.82      0.68        17\n",
            "        1422       0.57      0.87      0.68        15\n",
            "       14427       1.00      0.57      0.73        14\n",
            "       14455       0.75      0.23      0.35        13\n",
            "        1455       0.60      0.56      0.58        16\n",
            "       14619       0.67      0.33      0.44        12\n",
            "       14623       0.73      0.69      0.71        16\n",
            "       14674       0.81      0.76      0.79        17\n",
            "       14857       0.60      0.40      0.48        15\n",
            "       14864       0.75      0.64      0.69        14\n",
            "        1598       0.84      1.00      0.91        16\n",
            "        1675       0.86      0.75      0.80        16\n",
            "        1716       1.00      0.88      0.93        16\n",
            "        1782       0.74      0.93      0.82        15\n",
            "        2093       1.00      0.56      0.72        16\n",
            "        2164       0.68      0.81      0.74        16\n",
            "        2417       0.90      0.60      0.72        15\n",
            "         270       1.00      0.75      0.86        16\n",
            "        2725       0.54      0.88      0.67        16\n",
            "        3393       0.81      0.87      0.84        15\n",
            "         340       1.00      0.80      0.89        15\n",
            "        3638       0.79      0.69      0.73        16\n",
            "        3649       1.00      0.93      0.97        15\n",
            "        3719       1.00      0.73      0.85        15\n",
            "        3856       0.88      0.82      0.85        17\n",
            "        3950       1.00      0.62      0.77        16\n",
            "        4013       0.60      0.25      0.35        12\n",
            "        4098       0.93      0.81      0.87        16\n",
            "        4148       0.60      0.80      0.69        15\n",
            "        4251       0.60      0.60      0.60        15\n",
            "        4333       0.92      0.86      0.89        14\n",
            "        4390       0.68      1.00      0.81        15\n",
            "        4436       1.00      0.67      0.80        15\n",
            "        4771       1.00      0.94      0.97        17\n",
            "        5011       0.67      0.38      0.48        16\n",
            "        5103       0.59      0.87      0.70        15\n",
            "        5140       0.67      0.40      0.50        15\n",
            "        5234       0.92      0.80      0.86        15\n",
            "        5374       0.85      0.85      0.85        13\n",
            "        5466       0.43      0.50      0.46        12\n",
            "        5502       0.52      0.88      0.65        17\n",
            "        5931       0.71      0.31      0.43        16\n",
            "          60       0.72      1.00      0.84        13\n",
            "        6163       0.83      0.94      0.88        16\n",
            "         658       0.52      0.71      0.60        17\n",
            "        6768       0.92      0.75      0.83        16\n",
            "        6812       0.71      0.80      0.75        15\n",
            "        7052       0.88      0.47      0.61        15\n",
            "        7094       0.57      0.75      0.65        16\n",
            "         718       1.00      0.73      0.85        15\n",
            "        7263       0.82      0.93      0.87        15\n",
            "        7584       1.00      0.88      0.93        16\n",
            "        7905       0.58      0.93      0.72        15\n",
            "        7922       1.00      0.58      0.74        12\n",
            "        8006       0.85      0.92      0.88        12\n",
            "        8060       0.91      0.77      0.83        13\n",
            "        8264       0.84      0.94      0.89        17\n",
            "         838       0.56      0.88      0.68        16\n",
            "          86       0.79      0.69      0.73        16\n",
            "        8613       0.91      0.59      0.71        17\n",
            "        8718       0.85      0.79      0.81        14\n",
            "        8893       0.68      0.87      0.76        15\n",
            "        9033       1.00      0.75      0.86        16\n",
            "        9158       0.64      0.60      0.62        15\n",
            "        9215       0.72      0.81      0.76        16\n",
            "        9425       1.00      0.64      0.78        14\n",
            "        9530       0.71      0.62      0.67        16\n",
            "        9645       0.78      0.44      0.56        16\n",
            "        9665       1.00      0.94      0.97        16\n",
            "        9741       1.00      0.88      0.93        16\n",
            "        9763       0.77      0.91      0.83        11\n",
            "\n",
            "    accuracy                           0.74      1515\n",
            "   macro avg       0.78      0.74      0.74      1515\n",
            "weighted avg       0.78      0.74      0.74      1515\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}